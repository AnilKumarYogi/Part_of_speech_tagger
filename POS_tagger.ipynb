{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from io import open\n",
    "from io import StringIO\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "from sklearn_crfsuite import CRF\n",
    "from sklearn_crfsuite import metrics\n",
    "from sklearn_crfsuite import scorers\n",
    "from collections import Counter\n",
    "import scipy.stats\n",
    "from sklearn.metrics import make_scorer\n",
    "from sklearn.model_selection import RandomizedSearchCV, GridSearchCV, train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reading traing file\n",
    "data_file = open(\"hi-ud-train.conllu\",\"r\", encoding=\"utf-8\").read()\n",
    "string_data = StringIO(data_file)\n",
    "train = pd.read_csv(string_data, sep =\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# converting data file to trainable data\n",
    "def trainable_data(file):\n",
    "    file = file.replace(np.nan,\"###\", regex=True)\n",
    "    data_list = []\n",
    "    sen = []\n",
    "    tag_list = []\n",
    "    y = []\n",
    "    for i in range(len(file)):\n",
    "        if(file['WORD'][i]=='###'):\n",
    "            data_list.append(sen)\n",
    "            sen = []\n",
    "            tag_list.append(y)\n",
    "            y = []\n",
    "        \n",
    "        else:\n",
    "            sen.append(file['WORD'][i])\n",
    "            y.append(file['POS_TAG'][i])\n",
    "    return data_list,tag_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_list,y_train = trainable_data(train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Buliding the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Features Taken are:   \n",
    "##### 1) Is it the first word of the sentence?  \n",
    "Knowing if the given word is the first word of the sentence can help in providing greater emphasis on certain part of speech, for example a declarative sentence very often starts with a Noun as subject and with a Auxilary verb in case of an interogative sentence.  \n",
    "##### 2) Is it the last word of the sentence?  \n",
    "Punctuations very often marks the end of sentences.So taking into consideration if the given word is the last word in the sentence can provide vital information for PUNCT tag.  \n",
    "##### 3) What is the previous word and the next word?\n",
    "Certain part of speech tags go hand-in-hand and occurence of the first provide greater chnace for occurence of the second. For example, in hindi a Noun is often followed by prepostion or verb e.g. राम खेलता है, राम का घर, etc. Similarly, an Adjective very often comes before an Noun e.g. लाल कपडा,बडा घर, etc.  \n",
    "##### 4) What is the word before the previous word?  \n",
    "Taking the word before the previous word provides better contex to the following words.In addition to that in hindi words like दिन-रात,सुख-दुख etc. containing a hyphen sign in between them are very common and they are of same pos tag. Thus taking previos two words to train will make our model more robust.  \n",
    "##### 5) What is the word after the next word?\n",
    "This will also help in capturing the context of the word from the sentence.\n",
    "##### 6) Is it a numeric?\n",
    "For NUM pos tag this is important to distinguish pure numbers from non-numeric words.  \n",
    "##### 7) Is it alphanumeric?\n",
    "In train corpus there are words like 20वी which are alphanumeric hence to capture there attributes taking alphanumeric as feature seems vital.  \n",
    "##### 8) What is the prefix of the word?\n",
    "prefixes in hindi are very important to detremine the behaviour of word in the sentence.For example हारा is Ajective but तुम्हारा is Pronoun. \n",
    "##### 9) What is the suffix of the word?\n",
    "Suffixes in hindi often change the pos tag of root word, for example वह is Pronoun but वहां is Adverb."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def features(sentence,index):\n",
    "    # sentence is of the form [w1,w2,w3,..], index is the position of the word in the sentence\n",
    "    return {\n",
    "        'is_first_word': int(index==0),\n",
    "        'is_last_word':int(index==len(sentence)-1),\n",
    "        'prev_prev_word':'' if index==0 or index==1 else sentence[index-2], \n",
    "        'prev_word':'' if index==0 else sentence[index-1],\n",
    "        'next_word':'' if index==len(sentence)-1 else sentence[index+1],\n",
    "        'next_next_word':'' if index==len(sentence)-2 or index==len(sentence)-1 else sentence[index+2],\n",
    "        'is_numeric':int(sentence[index].isdigit()),\n",
    "        'is_alphanumeric': int(bool((re.match('^(?=.*[0-9]$)(?=.*[a-zA-Z])',sentence[index])))),\n",
    "        'prefix_1':sentence[index][0],\n",
    "        'prefix_2': sentence[index][:2],\n",
    "        'prefix_3':sentence[index][:3],\n",
    "        'prefix_4':sentence[index][:4],\n",
    "        'suffix_1':sentence[index][-1],\n",
    "        'suffix_2':sentence[index][-2:],\n",
    "        'suffix_3':sentence[index][-3:],\n",
    "        'suffix_4':sentence[index][-4:],  \n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepareData(data):\n",
    "    # data is of the form [[w1,w2,w3,..],[w1,w2,w3,..],...]\n",
    "    X_train = []\n",
    "    for i in range(len(data)):\n",
    "        temp = [] \n",
    "        for j in range(len(data[i])):\n",
    "            temp.append(features(data[i],j))\n",
    "        X_train.append(temp)\n",
    "    return X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = prepareData(train_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 50 candidates, totalling 150 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:   20.6s\n",
      "[Parallel(n_jobs=-1)]: Done 150 out of 150 | elapsed:  1.3min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=3, error_score='raise-deprecating',\n",
       "          estimator=CRF(algorithm='lbfgs', all_possible_states=None,\n",
       "  all_possible_transitions=True, averaging=None, c=None, c1=None, c2=None,\n",
       "  calibration_candidates=None, calibration_eta=None,\n",
       "  calibration_max_trials=None, calibration_rate=None,\n",
       "  calibration_samples=None, delta=None, epsilon=None, error...e,\n",
       "  num_memories=None, pa_type=None, period=None, trainer_cls=None,\n",
       "  variance=None, verbose=False),\n",
       "          fit_params=None, iid='warn', n_iter=50, n_jobs=-1,\n",
       "          param_distributions={'c1': <scipy.stats._distn_infrastructure.rv_frozen object at 0x7f98ac570c88>, 'c2': <scipy.stats._distn_infrastructure.rv_frozen object at 0x7f98655dc358>},\n",
       "          pre_dispatch='2*n_jobs', random_state=None, refit=True,\n",
       "          return_train_score='warn',\n",
       "          scoring=make_scorer(flat_f1_score, average=weighted), verbose=1)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Model buliding and hyperparameter optimazation\n",
    "crf = CRF(\n",
    "    algorithm='lbfgs',\n",
    "    max_iterations=100,\n",
    "    all_possible_transitions=True\n",
    ")\n",
    "params_space = {\n",
    "    'c1': scipy.stats.expon(scale=0.5),\n",
    "    'c2': scipy.stats.expon(scale=0.05),\n",
    "}\n",
    "\n",
    "f1_scorer = make_scorer(metrics.flat_f1_score,\n",
    "                        average='weighted')\n",
    "rs = RandomizedSearchCV(crf, params_space,\n",
    "                        cv=3,\n",
    "                        verbose=1,\n",
    "                        n_jobs=-1,\n",
    "                        n_iter=50,\n",
    "                        scoring=f1_scorer)\n",
    "\n",
    "rs.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best params: {'c1': 0.04259998226701805, 'c2': 0.01884534311587427}\n",
      "best CV score: 0.8543741387677777\n",
      "model size: 0.52M\n"
     ]
    }
   ],
   "source": [
    "# Values of c1 and c2 after hyperparameter tunning\n",
    "print('best params:', rs.best_params_)\n",
    "print('best CV score:', rs.best_score_)\n",
    "print('model size: {:0.2f}M'.format(rs.best_estimator_.size_ / 1000000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The overall accuracy on train set: 0.9998663816141101\n"
     ]
    }
   ],
   "source": [
    "# the overall accuracy of train set\n",
    "crf = rs.best_estimator_\n",
    "y_pred_train=crf.predict(X_train)\n",
    "print(f\"The overall accuracy on train set: {metrics.flat_accuracy_score(y_train,y_pred_train)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluating on test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reading test file\n",
    "test_file = open(\"hi-ud-test .conllu\",\"r\", encoding=\"utf-8\").read()\n",
    "test_string = StringIO(test_file)\n",
    "test = pd.read_csv(test_string,sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# preparing test data for evaluation\n",
    "test = test.replace(np.nan,\"###\", regex=True)\n",
    "test_list = []\n",
    "sen = []\n",
    "y_test = []\n",
    "y = []\n",
    "for i in range(len(test)):\n",
    "    if(test['WORD'][i]=='###'):\n",
    "        test_list.append(sen)\n",
    "        sen = []\n",
    "        y_test.append(y)\n",
    "        y = []\n",
    "        \n",
    "    else:\n",
    "        sen.append(test['WORD'][i])\n",
    "        y.append(test['TAG'][i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = prepareData(test_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Overall accuracy on test set: 0.8497229916897507\n"
     ]
    }
   ],
   "source": [
    "y_pred_test = crf.predict(X_test)\n",
    "result = metrics.flat_accuracy_score(y_test,y_pred_test)\n",
    "print(f\"The Overall accuracy on test set: {result}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analysing Transition features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of Transition Features: 159\n"
     ]
    }
   ],
   "source": [
    "print(f\"Total number of Transition Features: {len(crf.transition_features_)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(('VERB', 'AUX'), 4.810736),\n",
       " (('PROPN', 'PROPN'), 3.750578),\n",
       " (('ADJ', 'NOUN'), 3.495997),\n",
       " (('NUM', 'NOUN'), 2.940721),\n",
       " (('DET', 'NOUN'), 2.497383),\n",
       " (('NOUN', 'ADP'), 2.473905),\n",
       " (('PROPN', 'ADP'), 2.334321),\n",
       " (('VERB', 'SCONJ'), 2.027346),\n",
       " (('PART', 'NUM'), 1.912271),\n",
       " (('PRON', 'ADP'), 1.884884)]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 10 Most common transition features\n",
    "Counter(crf.transition_features_).most_common(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(('PROPN', 'AUX'), -1.465426),\n",
       " (('AUX', 'ADJ'), -1.487373),\n",
       " (('PROPN', 'DET'), -1.555321),\n",
       " (('CCONJ', 'PART'), -1.62782),\n",
       " (('DET', 'CCONJ'), -1.690419),\n",
       " (('PRON', 'CCONJ'), -1.761658),\n",
       " (('CCONJ', 'AUX'), -1.777492),\n",
       " (('ADJ', 'PRON'), -2.580376),\n",
       " (('ADJ', 'ADP'), -2.855517),\n",
       " (('DET', 'ADP'), -3.110945)]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 10 least common transition features\n",
    "Counter(crf.transition_features_).most_common()[-10:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         DET      1.000     1.000     1.000       230\n",
      "       PROPN      1.000     1.000     1.000       707\n",
      "         ADP      1.000     1.000     1.000      1384\n",
      "         ADV      1.000     1.000     1.000       110\n",
      "         ADJ      1.000     1.000     1.000       569\n",
      "        NOUN      1.000     1.000     1.000      1596\n",
      "         NUM      1.000     1.000     1.000       152\n",
      "         AUX      0.999     1.000     0.999       728\n",
      "       PUNCT      1.000     1.000     1.000       563\n",
      "        PRON      1.000     1.000     1.000       430\n",
      "        VERB      1.000     0.998     0.999       639\n",
      "       CCONJ      1.000     1.000     1.000       150\n",
      "        PART      1.000     1.000     1.000       163\n",
      "       SCONJ      1.000     1.000     1.000        61\n",
      "           X      1.000     1.000     1.000         2\n",
      "\n",
      "   micro avg      1.000     1.000     1.000      7484\n",
      "   macro avg      1.000     1.000     1.000      7484\n",
      "weighted avg      1.000     1.000     1.000      7484\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Precision, Recall, F-score per unique POS tag on the train set\n",
    "print(metrics.flat_classification_report(\n",
    "      y_train, y_pred_train, labels=crf.classes_, digits=3\n",
    "))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         DET      0.865     0.889     0.877        36\n",
      "       PROPN      0.606     0.535     0.568       144\n",
      "         ADP      0.955     0.970     0.962       303\n",
      "         ADV      0.688     0.524     0.595        21\n",
      "         ADJ      0.654     0.723     0.687        94\n",
      "        NOUN      0.789     0.855     0.821       324\n",
      "         NUM      0.885     0.920     0.902        25\n",
      "         AUX      0.943     0.957     0.950       138\n",
      "       PUNCT      1.000     0.836     0.911       134\n",
      "        PRON      0.862     0.862     0.862        65\n",
      "        VERB      0.885     0.859     0.872        99\n",
      "       CCONJ      1.000     1.000     1.000        25\n",
      "        PART      1.000     0.970     0.985        33\n",
      "       SCONJ      0.600     1.000     0.750         3\n",
      "           X      0.000     0.000     0.000         0\n",
      "\n",
      "   micro avg      0.850     0.850     0.850      1444\n",
      "   macro avg      0.782     0.793     0.783      1444\n",
      "weighted avg      0.851     0.850     0.849      1444\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/anil/anaconda3/lib/python3.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/anil/anaconda3/lib/python3.7/site-packages/sklearn/metrics/classification.py:1145: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "# Precision, Recall, F-score per unique POS tag on the test set\n",
    "print(metrics.flat_classification_report(\n",
    "    y_test, y_pred_test, labels=crf.classes_, digits=3\n",
    "))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
